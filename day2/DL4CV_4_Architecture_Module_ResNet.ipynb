{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "DL4CV - 4 - Architecture Module ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteoalberti/Lectures_AdvCV_Experis2020/blob/main/day2/DL4CV_4_Architecture_Module_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS7tyWwjU1zC"
      },
      "source": [
        "![](https://github.com/matteoalberti/Lectures_AdvCV_Experis2020/blob/main/day2/images/intro.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10A4Jc9KU1zE"
      },
      "source": [
        "# **Welcome!**\n",
        "\n",
        "## Introduction to Machine Learning for Computer Vision\n",
        "\n",
        "\n",
        "\n",
        "## **Lecturer :** Matteo Alberti\n",
        "\n",
        "![](data:image/jpeg;base64,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)\n",
        "\n",
        "*Contacts :* https://www.linkedin.com/in/matteo-alberti-170493/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfoVq_o6U1zG"
      },
      "source": [
        "# Summary\n",
        "\n",
        "- <font color=BE3315>**Introduction to Deep Models** </font> : Introduction to ResNet\n",
        "\n",
        "  -  <font color=E15234>**State-of-the-Art** </font> : [Variants]  \n",
        "\n",
        "  - <font color=E35F2A>**Transfer Learning & Pre-Trained Models** </font>\n",
        "\n",
        "- <font color=F4C52D>**Exercises & Tips** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxEVpk7tU1zH"
      },
      "source": [
        "## Start with Code: Step-by-Step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH4qzvtiU1zJ"
      },
      "source": [
        "#### Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD_VZZbCU1zK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDa8WLvCU1zR"
      },
      "source": [
        "## Load Cifar10 data from Local File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM5JWXdAU1zT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26aa0329-cf08-4d29-c0b9-82f441697ad5"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZHhpVQwU1zq"
      },
      "source": [
        "##### Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek53FsJLU1zq"
      },
      "source": [
        "#The range for each individual colour is 0-255\n",
        "x_train = x_train.astype('float32')/255 \n",
        "x_test = x_test.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkk2wveoU1zx"
      },
      "source": [
        "### Define HyperParameters & CNN Architecture\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFUUv9kLU1zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f429007-f750-413b-c64b-989342364dab"
      },
      "source": [
        "#Parameters\n",
        "import sys;import argparse; sys.argv=['']; del sys\n",
        "parser = argparse.ArgumentParser(description=\"CNN\")\n",
        "parser.add_argument('--epochs', default=20, type=int)\n",
        "parser.add_argument('--iter', default=100, type=int)\n",
        "parser.add_argument('--batch_size', default=128, type=int)\n",
        "parser.add_argument('--lr', default=0.001, type=float)\n",
        "\n",
        "#For VGG\n",
        "parser.add_argument('--weight_decay', default=0.0001, type=float)\n",
        "parser.add_argument('--dropout', default=0.5, type=float)\n",
        "\n",
        "\n",
        "parser.add_argument('--height', default=32, type=int)\n",
        "parser.add_argument('--width', default=32, type=int)\n",
        "parser.add_argument('--channel', default=3, type=int)\n",
        "parser.add_argument('--classes', default=10, type=int)\n",
        "\n",
        "#FOR RESNET\n",
        "parser.add_argument('--stack_n', type=int, default=25, metavar='NUMBER',\n",
        "                help='stack number n, total layers = 6 * n + 2 (default: 5)')\n",
        "\n",
        "parser.add_argument('--train', default=False)\n",
        "args = parser.parse_args()\n",
        "\n",
        "layers_res = 6 * args.stack_n + 2\n",
        "parser.add_argument('--layers_res', default=layers_res)\n",
        "\n",
        "#Extras\n",
        "parser.add_argument('--early_stop', default=3)\n",
        "\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "print(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=128, channel=3, classes=10, dropout=0.5, early_stop=3, epochs=20, height=32, iter=100, layers_res=152, lr=0.001, stack_n=25, train=False, weight_decay=0.0001, width=32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "087VArgjU1z2"
      },
      "source": [
        "# Thought Deep Convolutional Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLk3QlRSU1z3"
      },
      "source": [
        "### Comparative study :\n",
        "    \n",
        "    Model\t        n\t200-epoch_accuracy\tOriginal_paper_accuracy\t   sec/epoch_on_GTX1080Ti\n",
        "    ------------------------------------------------------------------------------------------\n",
        "    ResNet20   v1\t3\t       92.16 %\t\t\t91.25 %\t   \t         35     <-------------\n",
        "    ResNet32   v1\t5\t       92.46 %\t\t\t92.49 %\t\t\t\t\t50\n",
        "    ResNet44   v1\t7\t       92.50 %\t\t\t92.83 %\t\t\t\t\t70\n",
        "    ResNet56   v1\t9\t       92.71 %\t\t\t93.03 %\t\t\t\t\t90\n",
        "    ResNet110  v1\t18\t       92.65 %\t\t\t93.39+-.16 %\t     \t165\n",
        "    ResNet164  v1\t27\t         - %\t\t\t94.07 %\t\t\t\t\t -\n",
        "    ResNet1001 v1\tN/A\t        - %\t\t\t92.39 %\t\t\t \t    -\n",
        "    ------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVUUTFw0U1z4"
      },
      "source": [
        "# Residual Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TYW01MWVdhg"
      },
      "source": [
        "### The easy way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpLZVWJEVd1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23f6da6-3d5b-4c08-92fb-17f52308ec00"
      },
      "source": [
        "resnet50 = tf.keras.applications.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None,\n",
        "    pooling=None, classes=1000, classifier_activation='softmax')\n",
        "\n",
        "resnet50.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 25,636,712\n",
            "Trainable params: 25,583,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOqLDrYLVeCi"
      },
      "source": [
        "### Hard way!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8AZPpeSsCok"
      },
      "source": [
        "#### First of all! \n",
        "\n",
        "*How can I re-write this?*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ5JoZFXsASL"
      },
      "source": [
        "#Instantiate an empty model\n",
        "\n",
        "def build_VGG(input_shape, n_classes):\n",
        "  return tf.keras.models.Sequential([    \n",
        "  tf.keras.layers.Conv2D(64, (3, 3), input_shape=input_shape, padding='same', activation='relu'),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "  tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "  tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "  tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(4096, activation='relu'),\n",
        "  tf.keras.layers.Dense(4096, activation='relu'),\n",
        "  tf.keras.layers.Dense(n_classes, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywa8nObxsxNa"
      },
      "source": [
        "###VGG BLOCKS?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNbAfS7TsAK_"
      },
      "source": [
        "#Instantiate an empty model\n",
        "\n",
        "def VGG_blocks(n_conv, rec_field, act):\n",
        "  return tf.keras.models.Sequential([    \n",
        "  tf.keras.layers.Conv2D(n_conv, rec_field, padding='same', activation=act),\n",
        "  tf.keras.layers.Conv2D(n_conv, rec_field, activation=act, padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))])\n",
        "\n",
        "def CLASSIFICATION(n_dense, n_classes):\n",
        "  return tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(n_dense, activation='relu'),\n",
        "  tf.keras.layers.Dense(n_dense, activation='relu'),\n",
        "  tf.keras.layers.Dense(n_classes, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKPoCJV2tFvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc42f858-4bec-4b14-832b-a5289a91f025"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(32,32,3))\n",
        "\n",
        "x = VGG_blocks(n_conv=64, rec_field=(3,3), act='relu')(inputs)\n",
        "x = VGG_blocks(n_conv=128, rec_field=(3,3), act='relu')(x)\n",
        "x = VGG_blocks(n_conv=256, rec_field=(3,3), act='relu')(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "outputs = CLASSIFICATION(n_dense=4096, n_classes=100)(x)\n",
        "\n",
        "\n",
        "VGG_EASY = tf.keras.Model(inputs, outputs)\n",
        "VGG_EASY.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "sequential_11 (Sequential)   (None, 16, 16, 64)        38720     \n",
            "_________________________________________________________________\n",
            "sequential_12 (Sequential)   (None, 8, 8, 128)         221440    \n",
            "_________________________________________________________________\n",
            "sequential_13 (Sequential)   (None, 4, 4, 256)         885248    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "sequential_14 (Sequential)   (None, 100)               33972324  \n",
            "=================================================================\n",
            "Total params: 35,117,732\n",
            "Trainable params: 35,117,732\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic7k9LOTsAFv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EkbrtvTU1z5"
      },
      "source": [
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "\n",
        "n = 3\n",
        "version = 1\n",
        "\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_YfOG7HU1z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87d5662b-9c20-4ba0-d562-d9706a7b0a43"
      },
      "source": [
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version); print(model_type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet20v1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyaGTF5CU10C"
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtxJqCzkU10H"
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "  \n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "### COMPLETE!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2T5Ao6GU10L"
      },
      "source": [
        "## Residual Neural Network [V1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3URsWdCU10M"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = tf.keras.layers.add([x, y])\n",
        "            x = tf.keras.layers.Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = tf.keras.layers.AveragePooling2D(pool_size=8)(x)\n",
        "    y = tf.keras.layers.Flatten()(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IyX8QrbU10Q"
      },
      "source": [
        "model_v1 = resnet_v1(input_shape=(32,32,3), depth=depth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyNB9RjlU10U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca303436-1936-4d14-c427-ca421c7f3f37"
      },
      "source": [
        "#Compile architecture\n",
        "model_v1.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_v1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_2[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_4[0][0]               \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 32)   4640        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 32)   544         activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 32)   0           conv2d_9[0][0]                   \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 32)   0           activation_8[0][0]               \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           activation_10[0][0]              \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 64)     18496       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 64)     2112        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 64)     0           conv2d_16[0][0]                  \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 64)     0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 64)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 64)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 64)     0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42N0PC0uU10Y"
      },
      "source": [
        "model_name = 'pretrained_model/cifar10_%s_model.{epoch:03d}.h5' % model_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfeCP2R1U10d"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='logs/checkpoint/',\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj9V5VCYXv7r"
      },
      "source": [
        "# define callbacks\n",
        "\n",
        "%load_ext tensorboard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqd6h-u7U10h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69329267-d0e6-43fb-9643-1a4ef0ec561d"
      },
      "source": [
        "model_v1.fit(x_train, y_train,\n",
        "              batch_size=args.batch_size,\n",
        "              epochs=50, validation_split=0.2,\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.6790 - accuracy: 0.4550WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 31s 99ms/step - loss: 1.6790 - accuracy: 0.4550 - val_loss: 1.7163 - val_accuracy: 0.4477\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.2594 - accuracy: 0.6055WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 1.2594 - accuracy: 0.6055 - val_loss: 1.4688 - val_accuracy: 0.5405\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "312/313 [============================>.] - ETA: 0s - loss: 1.0711 - accuracy: 0.6703WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 1.0711 - accuracy: 0.6703 - val_loss: 1.3455 - val_accuracy: 0.6006\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.9434 - accuracy: 0.7186WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.9437 - accuracy: 0.7185 - val_loss: 1.4298 - val_accuracy: 0.6062\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.8434 - accuracy: 0.7550WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.8434 - accuracy: 0.7550 - val_loss: 1.0908 - val_accuracy: 0.6821\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.7566 - accuracy: 0.7852WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.7566 - accuracy: 0.7852 - val_loss: 1.2963 - val_accuracy: 0.6303\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.6881 - accuracy: 0.8137WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.6881 - accuracy: 0.8137 - val_loss: 1.3240 - val_accuracy: 0.6337\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.8353WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.6252 - accuracy: 0.8353 - val_loss: 1.1509 - val_accuracy: 0.6916\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.5711 - accuracy: 0.8568WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.5711 - accuracy: 0.8568 - val_loss: 1.2591 - val_accuracy: 0.6722\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.8734WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.5237 - accuracy: 0.8734 - val_loss: 1.3317 - val_accuracy: 0.6583\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.8923WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.4709 - accuracy: 0.8923 - val_loss: 1.1287 - val_accuracy: 0.7134\n",
            "Learning rate:  0.001\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.9086WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.4283 - accuracy: 0.9086 - val_loss: 1.1249 - val_accuracy: 0.7244\n",
            "Learning rate:  0.001\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.9210WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.3980 - accuracy: 0.9210 - val_loss: 1.5758 - val_accuracy: 0.6667\n",
            "Learning rate:  0.001\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.9279WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.3762 - accuracy: 0.9279 - val_loss: 1.8997 - val_accuracy: 0.6374\n",
            "Learning rate:  0.001\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.9377WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.3534 - accuracy: 0.9377 - val_loss: 1.6499 - val_accuracy: 0.6667\n",
            "Learning rate:  0.001\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.9405WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.3450 - accuracy: 0.9405 - val_loss: 1.5294 - val_accuracy: 0.6781\n",
            "Learning rate:  0.001\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.9469WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.3287 - accuracy: 0.9469 - val_loss: 1.5131 - val_accuracy: 0.6976\n",
            "Learning rate:  0.001\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.9476WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.3263 - accuracy: 0.9476 - val_loss: 1.3457 - val_accuracy: 0.7057\n",
            "Learning rate:  0.001\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.9551WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.3066 - accuracy: 0.9551 - val_loss: 1.4708 - val_accuracy: 0.7149\n",
            "Learning rate:  0.001\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.9560WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.3026 - accuracy: 0.9560 - val_loss: 1.4382 - val_accuracy: 0.7150\n",
            "Learning rate:  0.001\n",
            "Epoch 21/50\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.2984 - accuracy: 0.9587WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2984 - accuracy: 0.9587 - val_loss: 2.0443 - val_accuracy: 0.6262\n",
            "Learning rate:  0.001\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.9585WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.3013 - accuracy: 0.9585 - val_loss: 1.8898 - val_accuracy: 0.6635\n",
            "Learning rate:  0.001\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2966 - accuracy: 0.9611WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2966 - accuracy: 0.9611 - val_loss: 1.7797 - val_accuracy: 0.6770\n",
            "Learning rate:  0.001\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2860 - accuracy: 0.9639WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2860 - accuracy: 0.9639 - val_loss: 1.5474 - val_accuracy: 0.7091\n",
            "Learning rate:  0.001\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2987 - accuracy: 0.9600WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2987 - accuracy: 0.9600 - val_loss: 1.8494 - val_accuracy: 0.6690\n",
            "Learning rate:  0.001\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2826 - accuracy: 0.9661WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2826 - accuracy: 0.9661 - val_loss: 1.6113 - val_accuracy: 0.6828\n",
            "Learning rate:  0.001\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.9615WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2959 - accuracy: 0.9615 - val_loss: 2.3189 - val_accuracy: 0.6506\n",
            "Learning rate:  0.001\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.9715WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2698 - accuracy: 0.9715 - val_loss: 1.7427 - val_accuracy: 0.6933\n",
            "Learning rate:  0.001\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2881 - accuracy: 0.9649WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2881 - accuracy: 0.9649 - val_loss: 2.5234 - val_accuracy: 0.6305\n",
            "Learning rate:  0.001\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.9686WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2806 - accuracy: 0.9686 - val_loss: 1.4941 - val_accuracy: 0.7182\n",
            "Learning rate:  0.001\n",
            "Epoch 31/50\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.2857 - accuracy: 0.9666WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2857 - accuracy: 0.9667 - val_loss: 1.7776 - val_accuracy: 0.6646\n",
            "Learning rate:  0.001\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.9676WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2835 - accuracy: 0.9676 - val_loss: 2.0163 - val_accuracy: 0.6886\n",
            "Learning rate:  0.001\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.9701WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2760 - accuracy: 0.9701 - val_loss: 1.9107 - val_accuracy: 0.6947\n",
            "Learning rate:  0.001\n",
            "Epoch 34/50\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.2844 - accuracy: 0.9678WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2844 - accuracy: 0.9678 - val_loss: 1.8562 - val_accuracy: 0.7007\n",
            "Learning rate:  0.001\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.9703WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2783 - accuracy: 0.9703 - val_loss: 1.7950 - val_accuracy: 0.6837\n",
            "Learning rate:  0.001\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.9709WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2794 - accuracy: 0.9709 - val_loss: 1.7439 - val_accuracy: 0.6951\n",
            "Learning rate:  0.001\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2790 - accuracy: 0.9683WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2790 - accuracy: 0.9683 - val_loss: 2.0676 - val_accuracy: 0.6575\n",
            "Learning rate:  0.001\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.9737WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2684 - accuracy: 0.9737 - val_loss: 1.6461 - val_accuracy: 0.6958\n",
            "Learning rate:  0.001\n",
            "Epoch 39/50\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.9725WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2736 - accuracy: 0.9725 - val_loss: 2.4444 - val_accuracy: 0.6594\n",
            "Learning rate:  0.001\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.9725WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2717 - accuracy: 0.9725 - val_loss: 2.0285 - val_accuracy: 0.6707\n",
            "Learning rate:  0.001\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.9727WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2759 - accuracy: 0.9727 - val_loss: 1.9739 - val_accuracy: 0.6721\n",
            "Learning rate:  0.001\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2843 - accuracy: 0.9700WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2843 - accuracy: 0.9700 - val_loss: 1.4985 - val_accuracy: 0.7296\n",
            "Learning rate:  0.001\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.9751WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2684 - accuracy: 0.9751 - val_loss: 1.6741 - val_accuracy: 0.7180\n",
            "Learning rate:  0.001\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.9700WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2799 - accuracy: 0.9700 - val_loss: 1.9904 - val_accuracy: 0.6853\n",
            "Learning rate:  0.001\n",
            "Epoch 45/50\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.2843 - accuracy: 0.9693WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2844 - accuracy: 0.9692 - val_loss: 1.5710 - val_accuracy: 0.7166\n",
            "Learning rate:  0.001\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.9726WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2755 - accuracy: 0.9726 - val_loss: 2.6885 - val_accuracy: 0.6164\n",
            "Learning rate:  0.001\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2677 - accuracy: 0.9758WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.2677 - accuracy: 0.9758 - val_loss: 2.5082 - val_accuracy: 0.6542\n",
            "Learning rate:  0.001\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2546 - accuracy: 0.9808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2546 - accuracy: 0.9808 - val_loss: 1.4673 - val_accuracy: 0.7476\n",
            "Learning rate:  0.001\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.9714WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2786 - accuracy: 0.9714 - val_loss: 2.1454 - val_accuracy: 0.6955\n",
            "Learning rate:  0.001\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.9712WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.2804 - accuracy: 0.9712 - val_loss: 1.9999 - val_accuracy: 0.6723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f28c7a49a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbExn5KkU10k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2b8d71f3-ffd2-4d78-e596-4922e65f61f1"
      },
      "source": [
        "# Score trained model.\n",
        "scores = model_v1.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 11ms/step - loss: 2.0879 - accuracy: 0.6692\n",
            "Test loss: 2.087925672531128\n",
            "Test accuracy: 0.6692000031471252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqyZw0n6ZFh0"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF2bDNL0jXuj"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict the labels of the test set samples\n",
        "predicted_labels = model_v1.predict(x_test)\n",
        "\n",
        "# Build the confusion matrix of our 10-class classification problem\n",
        "cnf_matrix = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "disp = plot_confusion_matrix(model_v1, x_test, y_test,\n",
        "                                 display_labels=class_names,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kgxa8LNU10o"
      },
      "source": [
        "## Variants?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HHa24DvU10o"
      },
      "source": [
        "###### ResNetV2\n",
        "- Main difference : Batch normalization before each weight layer\n",
        "\n",
        "###### ResNext\n",
        "- different identity mappings building block\n",
        "    - different paths of stacked identity layers\n",
        "    - new hyperparameter \"cardinality\" for paths number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-1wCY1wU10p"
      },
      "source": [
        "## Residual Neural Network [V2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5vakMpWU10q"
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = tf.keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.AveragePooling2D(pool_size=8)(x)\n",
        "    y = tf.keras.layers.Flatten()(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOq8P6YwU10u"
      },
      "source": [
        "Paper 1 : [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n",
        "\n",
        "Paper 2 : [Dentity mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf)\n",
        "\n",
        "Paper 3 : [Aggregated Residual Transformation for Deep Neural Networks ](https://arxiv.org/pdf/1611.05431.pdf)\n",
        "\n",
        "Paper 4 : [Residual Networks Behave Like Ensembles of\n",
        "Relatively Shallow Networks\n",
        "](https://arxiv.org/pdf/1605.06431.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMdtCea_U10v"
      },
      "source": [
        "Real-world application to Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvx35gFlU103"
      },
      "source": [
        "## Why Learning Residual Neural Networks is so useful?\n",
        "\n",
        "    Because : \n",
        "\n",
        "    Poor Response:\n",
        "        1) State-of-the-art\n",
        "        2) We have many pre-trained models\n",
        "\n",
        "    Good Response:\n",
        "        3) Object Detection & Semantic Segmentation\n",
        "        4) Residual Learning is not just for computer vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nrEmHEcU104"
      },
      "source": [
        "###### 3) \"Object Detection\" -  \"Semantic Segmentation\"\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/groundai-web-prod/media%2Fusers%2Fuser_14%2Fproject_203625%2Fimages%2Fpaper_fig1.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOi1hgX1U104"
      },
      "source": [
        "# Best Practices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY5DLBleU105"
      },
      "source": [
        "### Networks comparison\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1UAMFe0DVD01waU-v0JcqEijWdNA6EBPX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVOG3zGigWPT"
      },
      "source": [
        "## How can I managed and use other pre-trained models?\n",
        "\n",
        "*Check tensorflow hub :* https://www.tensorflow.org/hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC5gTc0Vgsa_"
      },
      "source": [
        "*You'll find lots of models... also of NLP domain...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYQtqAfzU106"
      },
      "source": [
        "# [Interactive Session]\n",
        "\n",
        "*Here you'll find some extra exercises, just ignore them if you want. The main idea of these extra exercises is to make you focus on other possible aspects of ML models and implementations*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5mDQlBGbFmR"
      },
      "source": [
        "#### Question 1) \n",
        "\n",
        "    Check requirements of tf.keras.applications.ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPB1MNkubcWx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ea08278d-bdb8-4cf7-aef3-27e2a0c478ed"
      },
      "source": [
        "tf.keras.applications.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=(32,32,3),\n",
        "    pooling=None, classes=1000, classifier_activation='softmax')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-065f84e564ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tf.keras.applications.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=(32,32,3),\n\u001b[0;32m----> 2\u001b[0;31m     pooling=None, classes=1000, classifier_activation='softmax')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m   return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\n\u001b[0;32m--> 475\u001b[0;31m                 input_tensor, input_shape, pooling, classes, **kwargs)\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       weights=weights)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    343\u001b[0m         raise ValueError('When setting `include_top=True` '\n\u001b[1;32m    344\u001b[0m                          \u001b[0;34m'and loading `imagenet` weights, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                          '`input_shape` should be ' + str(default_shape) + '.')\n\u001b[0m\u001b[1;32m    346\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-cf-3KCb_fe"
      },
      "source": [
        "    Why this error? What can I do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYaqQ5S_U108"
      },
      "source": [
        "#### Exercise 1) \n",
        "\n",
        "    What happens to our networks's parameteres number if we convert our data from RGB to B/N? (*Tips : use openCV or numpy functions*)\n",
        "\n",
        "    Check also :\n",
        "\n",
        "    - Time to execution of our training?\n",
        "    - Accuracy?\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntA5x8PceE5b"
      },
      "source": [
        "### Try yourself before!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvrq3fxpdbwi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8C-HzFSddQ8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXdya2IPdb-4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzxz8gpLdcIF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV_qVnIddb6V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSNNZE4keBms"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj3oWCaPU108"
      },
      "source": [
        "def grayscale(data, dtype='float32'):\n",
        "    # luma coding weighted average in video systems\n",
        "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
        "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
        "    # add channel dimension\n",
        "    rst = np.expand_dims(rst, axis=3)\n",
        "    return rst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l82IXbnU11K",
        "outputId": "e4c1f7ab-3b92-460f-a669-ce5f15a9da06"
      },
      "source": [
        "x_train_gray = grayscale(x_train)\n",
        "x_test_gray = grayscale(x_test)\n",
        "x_val_gray = grayscale(x_val)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(x_train[0], interpolation='none')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(x_train_gray[0, :, :, 0], cmap=plt.get_cmap('gray'), interpolation='none')\n",
        "plt.show()\n",
        "\n",
        "print(x_train_gray.shape,y_train.shape, x_test_gray.shape,y_test.shape )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "height": 230,
              "width": 475
            }
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(7000, 32, 32, 1) (7000, 10) (1000, 32, 32, 1) (1000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpzV0Q1cU11R"
      },
      "source": [
        "#### Exercise 2-3) \n",
        "\n",
        "    - What is the gain in the number of parameters for VGG Net / ResNet?\n",
        "    - Calculate the difference in terms of time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8cMgnxLeKWI"
      },
      "source": [
        "### Try yourself before!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE_XoWFReKj1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxnAYmJrha41"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mfLrtKUhbI6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8onnJXCOha12"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN4KmNZLeKhB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98yXmSC8eMFw"
      },
      "source": [
        "### Solution!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOLZAnavU11T",
        "outputId": "9f240f5f-2756-46cc-f4b4-c41629aec7d1"
      },
      "source": [
        "lenet_base.count_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF6ntZVQU11d",
        "outputId": "4f76abbe-7505-4b06-92e8-5930014b7aa2"
      },
      "source": [
        "VGG_Net_rgb = VGG19(height=args.height, width=args.width, \n",
        "                channel=args.channel,classes=args.classes,\n",
        "                weight_decay=args.weight_decay, dropout=args.dropout,\n",
        "                pretrained_path='', summ=False)\n",
        "\n",
        "VGG_Net_bn = VGG19(height=args.height, width=args.width, \n",
        "                channel=1,classes=args.classes,\n",
        "                weight_decay=args.weight_decay, dropout=args.dropout,\n",
        "                pretrained_path='', summ=False)\n",
        "\n",
        "\n",
        "resnet_model_rgb = resnet_v1(input_shape=(args.height,args.width,args.channel),\n",
        "                         depth=args.layers_res, num_classes=args.classes,\n",
        "                        pretrained_path='',\n",
        "                        summ=False)\n",
        "\n",
        "resnet_model_bn = resnet_v1(input_shape=(args.height,args.width,args.channel),\n",
        "                         depth=args.layers_res, num_classes=1,\n",
        "                        pretrained_path='',\n",
        "                        summ=False)\n",
        "\n",
        "###########################################################################\n",
        "\n",
        "print('Difference for VGG : ', round((VGG_Net_rgb.count_params() - VGG_Net_bn.count_params())\n",
        "                                    /( VGG_Net_rgb.count_params())*100, 2))\n",
        "\n",
        "print('Difference for ResNet : ', round((resnet_model_rgb.count_params() - resnet_model_bn.count_params())\n",
        "                                    /( resnet_model_rgb.count_params())*100, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Difference for VGG :  0.0\n",
            "Difference for ResNet :  0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYYcQfzlU11j"
      },
      "source": [
        "##### Evaluate fit time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlPYR4LzU11k"
      },
      "source": [
        "# build network for RGB\n",
        "lenet_base_rgb = build_Lenet(height=args.height, width=args.width, channel=args.channel, classes=args.classes)\n",
        "# build network for BN\n",
        "lenet_base_bn = build_Lenet(height=args.height, width=args.width, channel=1, classes=args.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X-SogxOU11q"
      },
      "source": [
        "class TimeHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r539bsLmU11w"
      },
      "source": [
        "# set callback\n",
        "tb_cb = TensorBoard(log_dir='./logs', histogram_freq=0)\n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "time_callback = TimeHistory()\n",
        "\n",
        "cbks = [change_lr,tb_cb, time_callback]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqCZHciZU112",
        "outputId": "47ee228f-b4dc-486c-f951-7f81454a77e6"
      },
      "source": [
        "# start train\n",
        "history_lenet_rgb = lenet_base_rgb.fit(x_train, y_train,\n",
        "          batch_size=args.batch_size,\n",
        "          epochs=1,\n",
        "          callbacks=cbks,\n",
        "          validation_data=(x_val, y_val),\n",
        "          shuffle=True, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 2000 samples\n",
            "Epoch 1/1\n",
            "7000/7000 [==============================] - ETA: 11s - loss: 2.0879 - acc: 0.25 - ETA: 11s - loss: 2.0821 - acc: 0.23 - ETA: 11s - loss: 2.0888 - acc: 0.23 - ETA: 11s - loss: 2.0989 - acc: 0.23 - ETA: 11s - loss: 2.0816 - acc: 0.24 - ETA: 10s - loss: 2.0720 - acc: 0.26 - ETA: 10s - loss: 2.0594 - acc: 0.26 - ETA: 10s - loss: 2.0518 - acc: 0.26 - ETA: 10s - loss: 2.0474 - acc: 0.27 - ETA: 10s - loss: 2.0499 - acc: 0.27 - ETA: 10s - loss: 2.0463 - acc: 0.28 - ETA: 9s - loss: 2.0472 - acc: 0.2773 - ETA: 9s - loss: 2.0687 - acc: 0.270 - ETA: 9s - loss: 2.1134 - acc: 0.260 - ETA: 9s - loss: 2.1079 - acc: 0.262 - ETA: 9s - loss: 2.1033 - acc: 0.262 - ETA: 8s - loss: 2.1017 - acc: 0.258 - ETA: 8s - loss: 2.0981 - acc: 0.256 - ETA: 8s - loss: 2.0947 - acc: 0.257 - ETA: 8s - loss: 2.0905 - acc: 0.260 - ETA: 7s - loss: 2.0849 - acc: 0.262 - ETA: 7s - loss: 2.0802 - acc: 0.264 - ETA: 7s - loss: 2.0748 - acc: 0.264 - ETA: 7s - loss: 2.0706 - acc: 0.264 - ETA: 6s - loss: 2.0664 - acc: 0.263 - ETA: 6s - loss: 2.0631 - acc: 0.262 - ETA: 6s - loss: 2.0558 - acc: 0.263 - ETA: 6s - loss: 2.0541 - acc: 0.264 - ETA: 5s - loss: 2.0491 - acc: 0.266 - ETA: 5s - loss: 2.0481 - acc: 0.266 - ETA: 5s - loss: 2.0478 - acc: 0.265 - ETA: 5s - loss: 2.0421 - acc: 0.266 - ETA: 5s - loss: 2.0375 - acc: 0.266 - ETA: 4s - loss: 2.0327 - acc: 0.267 - ETA: 4s - loss: 2.0306 - acc: 0.268 - ETA: 4s - loss: 2.0270 - acc: 0.268 - ETA: 4s - loss: 2.0208 - acc: 0.271 - ETA: 3s - loss: 2.0198 - acc: 0.272 - ETA: 3s - loss: 2.0179 - acc: 0.273 - ETA: 3s - loss: 2.0189 - acc: 0.275 - ETA: 3s - loss: 2.0137 - acc: 0.277 - ETA: 3s - loss: 2.0096 - acc: 0.278 - ETA: 2s - loss: 2.0042 - acc: 0.279 - ETA: 2s - loss: 2.0019 - acc: 0.280 - ETA: 2s - loss: 2.0010 - acc: 0.280 - ETA: 2s - loss: 1.9985 - acc: 0.281 - ETA: 1s - loss: 1.9960 - acc: 0.282 - ETA: 1s - loss: 1.9954 - acc: 0.282 - ETA: 1s - loss: 1.9916 - acc: 0.283 - ETA: 1s - loss: 1.9889 - acc: 0.284 - ETA: 0s - loss: 1.9878 - acc: 0.284 - ETA: 0s - loss: 1.9859 - acc: 0.284 - ETA: 0s - loss: 1.9817 - acc: 0.285 - ETA: 0s - loss: 1.9794 - acc: 0.286 - 14s - loss: 1.9797 - acc: 0.2866 - val_loss: 12.4985 - val_acc: 0.2135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5n36PsyU119",
        "outputId": "6abc3d2f-e3aa-4701-f541-37245bff0043"
      },
      "source": [
        "times_rgb = time_callback.times; times_rgb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14.679846286773682]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8DCr-_uU12E",
        "outputId": "ef009750-07b9-44ef-eaa4-eafe41b884d4"
      },
      "source": [
        "# start train\n",
        "history_lenet_rgb = lenet_base_bn.fit(x_train_gray, y_train,\n",
        "          batch_size=args.batch_size,\n",
        "          epochs=1,\n",
        "          callbacks=cbks,\n",
        "          validation_data=(x_val_gray, y_val),\n",
        "          shuffle=True, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 2000 samples\n",
            "Epoch 1/1\n",
            "7000/7000 [==============================] - ETA: 12s - loss: 2.3882 - acc: 0.08 - ETA: 10s - loss: 2.3836 - acc: 0.08 - ETA: 9s - loss: 2.3805 - acc: 0.0938 - ETA: 8s - loss: 2.3747 - acc: 0.095 - ETA: 8s - loss: 2.3644 - acc: 0.101 - ETA: 8s - loss: 2.3618 - acc: 0.093 - ETA: 7s - loss: 2.3533 - acc: 0.099 - ETA: 7s - loss: 2.3479 - acc: 0.102 - ETA: 7s - loss: 2.3435 - acc: 0.103 - ETA: 6s - loss: 2.3391 - acc: 0.106 - ETA: 6s - loss: 2.3360 - acc: 0.105 - ETA: 6s - loss: 2.3341 - acc: 0.102 - ETA: 6s - loss: 2.3312 - acc: 0.102 - ETA: 6s - loss: 2.3286 - acc: 0.101 - ETA: 6s - loss: 2.3276 - acc: 0.101 - ETA: 5s - loss: 2.3262 - acc: 0.100 - ETA: 5s - loss: 2.3240 - acc: 0.102 - ETA: 5s - loss: 2.3228 - acc: 0.103 - ETA: 5s - loss: 2.3209 - acc: 0.102 - ETA: 5s - loss: 2.3201 - acc: 0.102 - ETA: 5s - loss: 2.3196 - acc: 0.103 - ETA: 5s - loss: 2.3180 - acc: 0.106 - ETA: 4s - loss: 2.3167 - acc: 0.108 - ETA: 4s - loss: 2.3149 - acc: 0.109 - ETA: 4s - loss: 2.3137 - acc: 0.110 - ETA: 4s - loss: 2.3120 - acc: 0.113 - ETA: 4s - loss: 2.3107 - acc: 0.117 - ETA: 4s - loss: 2.3098 - acc: 0.118 - ETA: 3s - loss: 2.3083 - acc: 0.123 - ETA: 3s - loss: 2.3070 - acc: 0.123 - ETA: 3s - loss: 2.3058 - acc: 0.125 - ETA: 3s - loss: 2.3045 - acc: 0.127 - ETA: 3s - loss: 2.3032 - acc: 0.128 - ETA: 3s - loss: 2.3021 - acc: 0.129 - ETA: 2s - loss: 2.3008 - acc: 0.130 - ETA: 2s - loss: 2.3005 - acc: 0.131 - ETA: 2s - loss: 2.2998 - acc: 0.131 - ETA: 2s - loss: 2.2988 - acc: 0.132 - ETA: 2s - loss: 2.2973 - acc: 0.132 - ETA: 2s - loss: 2.2963 - acc: 0.133 - ETA: 2s - loss: 2.2953 - acc: 0.133 - ETA: 1s - loss: 2.2939 - acc: 0.135 - ETA: 1s - loss: 2.2929 - acc: 0.136 - ETA: 1s - loss: 2.2921 - acc: 0.136 - ETA: 1s - loss: 2.2905 - acc: 0.138 - ETA: 1s - loss: 2.2899 - acc: 0.137 - ETA: 1s - loss: 2.2887 - acc: 0.137 - ETA: 1s - loss: 2.2874 - acc: 0.139 - ETA: 0s - loss: 2.2860 - acc: 0.140 - ETA: 0s - loss: 2.2847 - acc: 0.141 - ETA: 0s - loss: 2.2837 - acc: 0.141 - ETA: 0s - loss: 2.2819 - acc: 0.143 - ETA: 0s - loss: 2.2802 - acc: 0.144 - ETA: 0s - loss: 2.2792 - acc: 0.145 - 9s - loss: 2.2785 - acc: 0.1457 - val_loss: 13.0588 - val_acc: 0.1790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umZK40VyU12J",
        "outputId": "966dadea-3a24-4f93-a76f-5ffba5027ac5"
      },
      "source": [
        "times_bn = time_callback.times; times_bn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.374999046325684]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEhIP_3QU12Q",
        "outputId": "5670c981-f466-4186-b190-85aa443d5f1c"
      },
      "source": [
        "print('\\n Difference of time for 1 epochs : ', round((times_rgb[0] - times_bn[0])\n",
        "                                    /( times_rgb[0])*100, 2), '%')\n",
        "\n",
        "print('\\n Difference for real training of 200 epochs :', (times_rgb[0]*200 - times_bn[0]*200)/60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Difference of time for 1 epochs :  36.14 %\n",
            "\n",
            " Difference for real training of 200 epochs : 17.68282413482666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JKCpDDkEW0n"
      },
      "source": [
        "## Tranfer Learning with ResNet on Cifar100!!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M86ovlJNFnGF"
      },
      "source": [
        "# Load ResNet50 with imagenet weights!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK7wXgj6EXED"
      },
      "source": [
        "# Load Cifar100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqCFoJWEEdkI"
      },
      "source": [
        "# Lets adapt Cifar100 to ResNet!\n",
        "\n",
        "# tips!\n",
        "model = Sequential()\n",
        "model.add(UpSampling2D())\n",
        "model.add(UpSampling2D())\n",
        "model.add(UpSampling2D())\n",
        "model.add(resnet_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(.25))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYIh6b2vE4pg"
      },
      "source": [
        "# Set up as not trainable Batch Layers!!\n",
        "\n",
        "\n",
        "# Why???? : This is because the BN layer would be using statistics of training data, instead of one used for inference. Only if :\n",
        "# ...if the target dataset on which model is being trained on is different from the originally used training dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PncoY_tE4tV"
      },
      "source": [
        "# TRAIN!\n",
        "\n",
        "# How many epochs? 20 should be fine!!!!"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}